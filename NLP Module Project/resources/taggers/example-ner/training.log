2022-11-10 18:09:32,482 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:32,482 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)
  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=16, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-11-10 18:09:32,482 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:32,483 Corpus: "Corpus: 6 train + 6 dev + 6 test sentences"
2022-11-10 18:09:32,483 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:32,483 Parameters:
2022-11-10 18:09:32,483  - learning_rate: "0.050000"
2022-11-10 18:09:32,483  - mini_batch_size: "32"
2022-11-10 18:09:32,483  - patience: "3"
2022-11-10 18:09:32,483  - anneal_factor: "0.5"
2022-11-10 18:09:32,483  - max_epochs: "3"
2022-11-10 18:09:32,483  - shuffle: "True"
2022-11-10 18:09:32,483  - train_with_dev: "False"
2022-11-10 18:09:32,483  - batch_growth_annealing: "False"
2022-11-10 18:09:32,483 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:32,483 Model training base path: "resources\taggers\example-ner"
2022-11-10 18:09:32,483 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:32,483 Device: cpu
2022-11-10 18:09:32,483 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:32,483 Embeddings storage mode: cpu
2022-11-10 18:09:32,483 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:35,004 epoch 1 - iter 1/1 - loss 4.09951268 - samples/sec: 12.69 - lr: 0.050000
2022-11-10 18:09:35,004 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:35,004 EPOCH 1 done: loss 4.0995 - lr 0.050000
2022-11-10 18:09:37,361 Evaluating as a multi-label problem: False
2022-11-10 18:09:37,365 DEV : loss 3.4932498931884766 - f1-score (micro avg)  0.0
2022-11-10 18:09:37,365 BAD EPOCHS (no improvement): 0
2022-11-10 18:09:37,366 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:37,612 epoch 2 - iter 1/1 - loss 3.53355135 - samples/sec: 130.15 - lr: 0.050000
2022-11-10 18:09:37,612 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:37,612 EPOCH 2 done: loss 3.5336 - lr 0.050000
2022-11-10 18:09:37,689 Evaluating as a multi-label problem: False
2022-11-10 18:09:37,694 DEV : loss 2.9411308765411377 - f1-score (micro avg)  0.0
2022-11-10 18:09:37,694 BAD EPOCHS (no improvement): 0
2022-11-10 18:09:37,694 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:37,947 epoch 3 - iter 1/1 - loss 2.97037771 - samples/sec: 126.28 - lr: 0.050000
2022-11-10 18:09:37,947 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:37,947 EPOCH 3 done: loss 2.9704 - lr 0.050000
2022-11-10 18:09:38,019 Evaluating as a multi-label problem: False
2022-11-10 18:09:38,023 DEV : loss 2.3462555408477783 - f1-score (micro avg)  0.0
2022-11-10 18:09:38,024 BAD EPOCHS (no improvement): 0
2022-11-10 18:09:41,773 ----------------------------------------------------------------------------------------------------
2022-11-10 18:09:41,773 Testing using last state of model ...
2022-11-10 18:09:44,157 Evaluating as a multi-label problem: False
2022-11-10 18:09:44,161 0.0	0.0	0.0	0.0
2022-11-10 18:09:44,161 
Results:
- F-score (micro) 0.0
- F-score (macro) 0.0
- Accuracy 0.0

By class:
              precision    recall  f1-score   support

     geo-loc     0.0000    0.0000    0.0000       1.0
       movie     0.0000    0.0000    0.0000       1.0
    facility     0.0000    0.0000    0.0000       0.0
      person     0.0000    0.0000    0.0000       3.0
       other     0.0000    0.0000    0.0000       1.0
     company     0.0000    0.0000    0.0000       1.0

   micro avg     0.0000    0.0000    0.0000       7.0
   macro avg     0.0000    0.0000    0.0000       7.0
weighted avg     0.0000    0.0000    0.0000       7.0

2022-11-10 18:09:44,161 ----------------------------------------------------------------------------------------------------
